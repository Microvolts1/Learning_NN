{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fully_connected_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSphOj1O5x5nfh1DlEh/ru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Microvolts1/Learning_NN/blob/main/Fully_connected_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thực hiện thiết kế\n"
      ],
      "metadata": {
        "id": "bbL1slD9zP2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer by layer\n",
        "- Ta thiết kế luồng hoạt động như sau:\n",
        "\n",
        "\n",
        "1.   Đầu tiên cho dữ liệu đầu vào NN.\n",
        "2.   Dữ liệu tiếp tục đi qua các layer khác nhau cho tới layer output.\n",
        "3.   Khi đã có output, ta có thể tính độ lỗi dùng làm độ đo.\n",
        "4.   Cuối cùng là điều chỉnh các tham số(weight - trọng số hoặc bias) bằng cách đạo hàm qua từng lớp tham số.\n",
        "5.   Lặp lại quá trình trên\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AVokv5U9GyYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mỗi layer gồm có:\n",
        "\n",
        "- Mỗi layer bất kì đều có điểm chung là input data và output data.\n",
        "<img src='https://miro.medium.com/max/1252/0*3cUc4jsQlHsoovn9.png'>\n",
        "\n"
      ],
      "metadata": {
        "id": "OSY219IkLHnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward propagation - Lan truyền tiến.\n",
        "\n",
        "- Nghĩa là output của layer trước sẽ là input của lớp sau đó.\n",
        "<img src='https://miro.medium.com/max/1352/1*ddDKxWSAYci2dHaG3O_DOg.png'>\n",
        "\n",
        "- Khi đó, tại layer cuối ta sẽ cho ra output, ta gọi là $\\hat{Y}$, có giá trị sẽ lệch so với giá trị $Y$ thật. Lúc này ta sẽ tính toán độ lỗi $E$ thông qua hai giá trị trước đó, và mục đích tính toán độ lỗi nhằm để điều chỉnh các tham số nhằm giảm thiểu độ lỗi nhỏ nhất có thể. Và các điều chỉnh đó gọi là Backward propagation - Lan truyền ngược. \n",
        "\n"
      ],
      "metadata": {
        "id": "hUrP5mRaLiHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent.\n",
        "\n",
        "- Liên quan tới việc sử dụng đạo hàm, cụ thể hơn là ta sẽ điều chỉnh tham số $w$ trong NN nhằm mục đích giảm thiểu độ lỗi $E$ và đạo hàm là một trong những phương pháp hay để giải quyết.\n",
        "\n",
        "<img src='https://miro.medium.com/max/620/0*MZYPbIwBn5SOEpG7.png'   align=\"center\">\n",
        "\n",
        "- $\\alpha$ là gọi là learning rate với miền giá trị trong khoảng $[0,1]$"
      ],
      "metadata": {
        "id": "BdU_O3zUORyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backward Propagation - Lan truyền ngược.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "64H4dxXvQVFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Giả sử ta đã có output $Y$, ta sẽ thực hiện đạo hàm trên độ lỗi $E$ với output $Y$ và thực hiện ngược lại cho tới lớp input $X$.\n",
        "<img src='https://miro.medium.com/max/1400/0*bL0jVGoQiH_TsrvT.png'>\n",
        "\n",
        "- Lưu ý rằng $E$ là một con số còn $X$ và $Y$ là ma trận.\n",
        "\n",
        "<img src='https://miro.medium.com/max/1052/0*KYFYEbu_o9j1_a5w.png'>\n",
        "\n",
        "\n",
        "- Và để tính được $\\frac{\\partial{E}}{\\partial{w}}$ thì áp dụng công thức toán học chain rule trong đạo hàm để tính toán:\n",
        "\n",
        "<img src='https://miro.medium.com/max/650/0*3xceKA-7b2oNbE4T.png'>"
      ],
      "metadata": {
        "id": "wExDonC-fPaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tiếp đến ta tính $\\frac{\\partial{E}}{\\partial{X}}$, lý do cần tính là vì output của layer này sẽ là input của layer khác nên ta cũng phải tính toán để có thể lan truyền đi tốt hơn.\n",
        "- Cũng sử dụng chain rule để ta có thể tính toán dễ dàng: \n",
        "\n",
        "\n",
        "<img src='https://miro.medium.com/max/658/0*Of8qDiWo31MK-MU0.png'>\n",
        "\n"
      ],
      "metadata": {
        "id": "kubbid2mfQ_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sơ đồ mô phong cách thức hoạt động của lan truyền ngược:\n",
        "1. Ban đầu ta có: \n",
        "\n",
        "<img src='https://miro.medium.com/max/1352/1*ddDKxWSAYci2dHaG3O_DOg.png'>\n",
        "\n",
        "\n",
        "2. Sau đó thực hiện lan truyền ngược:\n",
        "\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/1*0QPRST83oBicKPE_R4biJA.png'>"
      ],
      "metadata": {
        "id": "_Hm3SUTpf6Wq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code layer"
      ],
      "metadata": {
        "id": "XgWkDnrPgeb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base class Layer:\n",
        "- Đây sẽ là Base layer mà các Layer sẽ kế thừa. Chứa các thuộc tính đơn giản là input từ layer khác và output truyền đi. Kèm với phương thức foward và backward propagation."
      ],
      "metadata": {
        "id": "fa_4igHNgnc_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igaj160UyjN8"
      },
      "outputs": [],
      "source": [
        "# Base class\n",
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    # computes the output Y of a layer for a given input X\n",
        "    def forward_propagation(self, input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8_i2m0xphBtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fully Connected Layer."
      ],
      "metadata": {
        "id": "qTNDT1Zrh9cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Đây là layer cơ bản nhất: Mỗi input nơ-ron sẽ nối hết tới tất cả output nơ-ron ở layer kế tiếp nó.\n",
        "\n",
        "<img src='https://miro.medium.com/max/876/1*jOObSF4HAB5VL5wO6petqA.png'>"
      ],
      "metadata": {
        "id": "5ZitjDzeiElW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward propagation."
      ],
      "metadata": {
        "id": "YVuhStL2oQW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Việc lan tuyền tiến(Forward propagation) thực hiện như sau:\n",
        "\n",
        "<img src='https://miro.medium.com/max/674/0*Ec9fiXkNOoA5Z2v5.png'>\n",
        "\n",
        "- Với việc chúng ta sử dụng mà trận thì chúng ta có tích vô hướng (dot product) như sau:\n",
        "\n",
        "1. Ta có các ma trận:\n",
        "\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/0*qTBPwmzIjBOGKpXH.png'>\n",
        "\n",
        "\n",
        "2. Từ đó ta có được:\n",
        "\n",
        "\n",
        "<img src='https://miro.medium.com/max/506/0*FsJQ82GmKlV2X22z.png'>"
      ],
      "metadata": {
        "id": "tQNAmbo4iEp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "92GOflNQoX2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backward propagation.\n"
      ],
      "metadata": {
        "id": "Lv8H9_AMoXM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Giả sử chúng ta đã có $Y$ và $E$. "
      ],
      "metadata": {
        "id": "mLZ1Dq1BowUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0jr--u2rowaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C6evdmmENLna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vOFRD6B1IEgL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}